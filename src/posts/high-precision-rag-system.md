---
title: æ„å»ºåŸºäºERNIEä¸Milvusçš„å¤šæ–‡æ¡£é«˜ç²¾åº¦åˆ†æä¸é—®ç­”ç³»ç»Ÿ
date: 2025-12-01
author:
   name: å»–é›¨è²
   github: LiaoYFBH
tags:
   - RAG
   - Milvus
   - NLP
   - Python
category: community-activity
---

## å¼•è¨€

åœ¨å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„åº”ç”¨è½åœ°ä¸­ï¼ŒRAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æ˜¯è§£å†³æ¨¡å‹å¹»è§‰å’ŒçŸ¥è¯†æ—¶æ•ˆæ€§çš„å…³é”®æŠ€æœ¯ã€‚æœ¬åšå®¢å°†å¯¹æœ¬å¤šæ–‡æ¡£é«˜ç²¾åº¦æ™ºèƒ½åˆ†æä¸é—®ç­”ç³»ç»Ÿçš„å…³é”®æŠ€æœ¯è¿›è¡Œè¯´æ˜ä»‹ç»ã€‚è¯¥ç³»ç»Ÿé›†æˆäº† **åœ¨çº¿ OCR è§£æ**ã€**Milvus æ··åˆæ£€ç´¢ï¼ˆå‘é‡+å…³é”®è¯ï¼‰** ä»¥åŠ **å¤šç»´åº¦çš„é‡æ’åºï¼ˆRerankerï¼‰** ç­–ç•¥ï¼Œæ—¨åœ¨æå‡ä½èµ„æºç¯å¢ƒä¸‹çš„æ£€ç´¢å‡†ç¡®ç‡ï¼Œä»¥å®ç°é«˜ç²¾åº¦å¤šæ–‡æ¡£åˆ†æä¸é—®ç­”ã€‚

## 1. ç³»ç»Ÿæ¶æ„æ¦‚è§ˆ

æœ¬é¡¹ç›®çš„ç³»ç»Ÿä¸»è¦ç”±å››ä¸ªæ ¸å¿ƒæ¨¡å—ç»„æˆï¼š

1. **æ•°æ®æå–å±‚**ï¼šä½¿ç”¨åœ¨çº¿ OCR API è¿›è¡Œé«˜ç²¾åº¦çš„æ–‡æ¡£å¸ƒå±€åˆ†æï¼ˆLayout Parsingï¼‰ã€‚
2. **å­˜å‚¨å±‚**ï¼šåˆ©ç”¨ Milvus å‘é‡æ•°æ®åº“å­˜å‚¨ Dense Embeddingï¼ŒåŒæ—¶ç»´æŠ¤å€’æ’ç´¢å¼•ä»¥æ”¯æŒå…³é”®è¯æ£€ç´¢ã€‚
3. **æ£€ç´¢ä¸é—®ç­”å±‚**ï¼šå®ç°å‘é‡æ£€ç´¢ä¸å…³é”®è¯æ£€ç´¢çš„åŠ æƒèåˆï¼ˆRRFï¼‰ï¼Œé›†æˆ ERNIE å¤§æ¨¡å‹ API æ¥å£ç”Ÿæˆå›ç­”ã€‚
4. **åº”ç”¨å±‚**ï¼šåŸºäº Gradio æ„å»ºäº¤äº’ç•Œé¢ã€‚
<div style="display: flex; justify-content: center;">
  <img src="../images/high-precision-rag-system/flow.jpg" alt="Fig 2" style="width: 80%;">
</div>

### ğŸ”— é¡¹ç›®èµ„æº

- ğŸ™ GitHub ä»£ç ä»“åº“ï¼š[ç‚¹å‡»è®¿é—®](https://github.com/LiaoYFBH/Paddle-ERNIE-RAG)

- ğŸš€ æ˜Ÿæ²³ç¤¾åŒºåœ¨çº¿åº”ç”¨ï¼š[ç«‹å³ä½“éªŒ](https://aistudio.baidu.com/application/detail/107183)

- ğŸ““ æ˜Ÿæ²³ç¤¾åŒº Notebookï¼š[åœ¨çº¿è¿è¡Œ](https://aistudio.baidu.com/project/edit/9812333)

## 2. å…³é”®æŠ€æœ¯å®ç°

### 2.1 PP-StructureV3 æ–‡æ¡£è§£æ

é’ˆå¯¹ç§‘ç ”è®ºæ–‡ä¸­å¸¸è§çš„åŒæ æ’ç‰ˆã€å…¬å¼æ··æ’åŠå›¾è¡¨åµŒå…¥é—®é¢˜ï¼Œä¼ ç»Ÿçš„ PyPDF2 ç­‰çº¯æ–‡æœ¬æå–å·¥å…·å¾€å¾€åŠ›ä¸ä»å¿ƒï¼ˆå®¹æ˜“å¯¼è‡´æ®µè½ä¹±åºã€è¡¨æ ¼å´©åï¼‰ã€‚

ä¸ºæ­¤ï¼Œæœ¬é¡¹ç›®åœ¨ backend.py ä¸­å°è£…äº† OnlinePDFParser ç±»ï¼Œç›´æ¥é›†æˆ PP-StructureV3 åœ¨çº¿ API è¿›è¡Œé«˜ç²¾åº¦çš„æ–‡æ¡£å¸ƒå±€åˆ†æï¼ˆLayout Parsingï¼‰ã€‚

è¯¥æ–¹æ¡ˆå…·å¤‡ä¸‰å¤§æ ¸å¿ƒä¼˜åŠ¿ï¼š

- **ç»“æ„åŒ–è¾“å‡º**ï¼šç›´æ¥è¿”å› Markdown æ ¼å¼ï¼ˆè‡ªåŠ¨è¯†åˆ«æ ‡é¢˜å±‚çº§ã€æ®µè½è¾¹ç•Œï¼‰ã€‚

- **å›¾è¡¨æå–**ï¼šåœ¨è§£ææ–‡æœ¬çš„åŒæ—¶ï¼Œè‡ªåŠ¨æå–æ–‡æ¡£ä¸­çš„å›¾ç‰‡å¹¶è½¬å­˜ï¼Œä¸ºåç»­çš„â€œå¤šæ¨¡æ€é—®ç­”â€æä¾›ç´ æã€‚

- **ä¸Šä¸‹æ–‡ä¿ç•™**ï¼šåŸºäºæ»‘åŠ¨çª—å£è¿›è¡Œåˆ‡åˆ†ï¼Œé˜²æ­¢å…³é”®ä¿¡æ¯åœ¨åˆ‡ç‰‡è¾¹ç•Œä¸¢å¤±ã€‚

#### 2.1.1 æ ¸å¿ƒè§£æé€»è¾‘

åœ¨ backend.py ä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº† API è¯·æ±‚ï¼Œå°† PDF æ–‡ä»¶æµå‘é€è‡³æœåŠ¡ç«¯ï¼Œå¹¶è§£æè¿”å›çš„ layoutParsingResultsï¼Œæå–å‡ºæ¸…æ´—åçš„ Markdown æ–‡æœ¬å’Œå›¾ç‰‡èµ„æºã€‚

```python
# backend.py (OnlinePDFParser ç±»æ ¸å¿ƒé€»è¾‘æ‘˜è¦)
def predict(self, file_path):
    # 1. æ–‡ä»¶è½¬ Base64
    with open(file_path, "rb") as file:
        file_data = base64.b64encode(file.read()).decode("ascii")

    # 2. æ„é€ è¯·æ±‚ Payload
    payload = {
        "file": file_data,
        "fileType": 1, # PDF ç±»å‹
        "useChartRecognition": False, # æ ¹æ®éœ€æ±‚é…ç½®
        "useDocOrientationClassify": False
    }

    # 3. å‘é€è¯·æ±‚è·å– Layout Parsing ç»“æœ
    response = requests.post(self.api_url, json=payload, headers=headers)
    res_json = response.json()

    # 4. æå– Markdown æ–‡æœ¬ä¸å›¾ç‰‡
    parsing_results = res_json.get("result", {}).get("layoutParsingResults", [])
    mock_outputs = []
    for item in parsing_results:
        md_text = item.get("markdown", {}).get("text", "")
        images = item.get("markdown", {}).get("images", {})
        # ... (åç»­å›¾ç‰‡ä¸‹è½½ä¸æ–‡æœ¬æ¸…æ´—é€»è¾‘)
        mock_outputs.append(MockResult(md_text, images))

    return mock_outputs, "Success"
```

#### 2.1.2 æ»‘åŠ¨çª—å£æ–‡æœ¬åˆ†å—

æ‹¿åˆ°ç»“æ„åŒ–çš„ Markdown æ–‡æœ¬åï¼Œä¸ºäº†é¿å…è¯­ä¹‰è¢«ç”Ÿç¡¬åˆ‡æ–­ï¼ˆä¾‹å¦‚ä¸€å¥è¯è·¨äº†ä¸¤ä¸ª chunkï¼‰ï¼Œæˆ‘ä»¬å®ç°äº†ä¸€ä¸ªå¸¦æœ‰ overlapï¼ˆé‡å åŒºï¼‰çš„æ»‘åŠ¨çª—å£åˆ†å—ç­–ç•¥ã€‚

```python
# backend.py
def split_text_into_chunks(text: str, chunk_size: int = 300, overlap: int = 120) -> list:
    """åŸºäºæ»‘åŠ¨çª—å£çš„æ–‡æœ¬åˆ†å—ï¼Œä¿ç•™ overlap é•¿åº¦çš„é‡å ä¸Šä¸‹æ–‡"""
    if not text: return []
    lines = [line.strip() for line in text.split("\n") if line.strip()]
    chunks = []
    current_chunk = []
    current_length = 0

    for line in lines:
        while len(line) > chunk_size:
            # å¤„ç†è¶…é•¿å•è¡Œ
            part = line[:chunk_size]
            line = line[chunk_size:]
            current_chunk.append(part)
            # ... (åˆ‡åˆ†é€»è¾‘) ...

        current_chunk.append(line)
        current_length += len(line)

        # å½“ç´¯ç§¯é•¿åº¦è¶…è¿‡é˜ˆå€¼ï¼Œç”Ÿæˆä¸€ä¸ª chunk
        if current_length > chunk_size:
            chunks.append("\n".join(current_chunk))
            # å›é€€ï¼šä¿ç•™æœ€å overlap é•¿åº¦çš„æ–‡æœ¬ä½œä¸ºä¸‹ä¸€ä¸ª chunk çš„å¼€å¤´
            overlap_text = current_chunk[-1][-overlap:] if current_chunk else ""
            current_chunk = [overlap_text] if overlap_text else []
            current_length = len(overlap_text)

    if current_chunk:
        chunks.append("\n".join(current_chunk).strip())
    return chunks
```

### 2.2 Milvus å‘é‡åº“ä¸æ··åˆæ£€ç´¢ç­–ç•¥

#### 2.2.1 çŸ¥è¯†åº“å‘½åçš„å·¥ç¨‹åŒ–å¤„ç†

åœ¨å®é™…éƒ¨ç½²ä¸­ï¼ŒMilvus ç­‰å‘é‡æ•°æ®åº“å¯¹é›†åˆåç§°ï¼ˆCollection Nameï¼‰é€šå¸¸æœ‰ä¸¥æ ¼çš„å‘½åé™åˆ¶ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œæˆ‘ä»¬åœ¨åç«¯ä»£ç ä¸­å®ç°äº†ä¸€å¥—é€æ˜çš„ç¼–è§£ç æœºåˆ¶ã€‚

1. **ç¼–ç  (Encode)**ï¼šå½“ç”¨æˆ·åˆ›å»ºå¦‚â€œç‰©ç†è®ºæ–‡â€çš„åº“æ—¶ï¼Œç³»ç»Ÿå°†å…¶ UTF-8 å­—èŠ‚è½¬æ¢ä¸º Hex å­—ç¬¦ä¸²ï¼Œå¹¶æ·»åŠ  `kb_` å‰ç¼€ã€‚
2. **è§£ç  (Decode)**ï¼šåœ¨å‰ç«¯å±•ç¤ºæ—¶ï¼Œè‡ªåŠ¨å°† Hex å­—ç¬¦ä¸²åè§£ä¸ºåŸå§‹ä¸­æ–‡ã€‚

```python
import binascii
import re

def encode_name(ui_name):
    """æŠŠä¸­æ–‡åç§°è½¬ä¸º Milvus åˆæ³•çš„ Hex å­—ç¬¦ä¸²"""
    if not ui_name: return ""
    # å¦‚æœæ˜¯çº¯è‹±æ–‡/æ•°å­—/ä¸‹åˆ’çº¿ï¼Œç›´æ¥è¿”å›
    if re.match(r'^[a-zA-Z_][a-zA-Z0-9_]*$', ui_name):
        return ui_name

    # Hex ç¼–ç å¹¶åŠ å‰ç¼€ kb_
    hex_str = binascii.hexlify(ui_name.encode('utf-8')).decode('utf-8')
    return f"kb_{hex_str}"

def decode_name(real_name):
    """æŠŠ Hex å­—ç¬¦ä¸²è½¬å›ä¸­æ–‡"""
    if real_name.startswith("kb_"):
        try:
            hex_str = real_name[3:]
            return binascii.unhexlify(hex_str).decode('utf-8')
        except:
            return real_name
    return real_name
```

#### 2.2.2 å‘é‡åŒ–å…¥åº“ä¸å…ƒæ•°æ®ç»‘å®š

åœ¨ OCR è§£æå¹¶å°†é•¿æ–‡æœ¬åˆ‡åˆ†ä¸º Chunks åï¼Œç³»ç»Ÿå¹¶éç®€å•åœ°å°†æ–‡æœ¬å­˜å…¥æ•°æ®åº“ï¼Œè€Œæ˜¯æ‰§è¡Œäº† **â€œå‘é‡åŒ– + å…ƒæ•°æ®ç»‘å®šâ€** çš„å…³é”®æ­¥éª¤ã€‚

ä¸ºäº†æ”¯æŒåç»­çš„ç²¾ç¡®æº¯æºï¼ˆCitationï¼‰å’Œå¤šæ¨¡æ€é—®ç­”ï¼Œæˆ‘ä»¬åœ¨è®¾è®¡ Milvus Schema æ—¶ï¼Œé™¤äº†å­˜å‚¨ 384 ç»´çš„ Dense Vector å¤–ï¼Œè¿˜å¼ºåˆ¶ç»‘å®šäº† filenameï¼ˆæ–‡ä»¶åï¼‰ã€pageï¼ˆé¡µç ï¼‰å’Œ chunk_idï¼ˆåˆ‡ç‰‡ IDï¼‰ç­‰æ ‡é‡å­—æ®µã€‚

è¿™ä¸€è¿‡ç¨‹åœ¨ vector_store.py ä¸­é€šè¿‡ insert_documents æ–¹æ³•å®ç°ï¼Œé‡‡ç”¨æ‰¹é‡ Embedding ç­–ç•¥ä»¥å‡å°‘ç½‘ç»œå¼€é”€ï¼š

```python
# vector_store.py
def insert_documents(self, documents):
    """æ‰¹é‡å‘é‡åŒ–å¹¶å†™å…¥ Milvus"""
    if not documents: return

    # 1. æå–çº¯æ–‡æœ¬åˆ—è¡¨ï¼Œæ‰¹é‡è¯·æ±‚ Embedding æ¨¡å‹
    texts = [doc['content'] for doc in documents]
    embeddings = self.get_embeddings(texts)

    # 2. æ•°æ®æ¸…æ´—ï¼šè¿‡æ»¤æ‰ Embedding å¤±è´¥çš„åæ•°æ®
    valid_docs, valid_vectors = [], []
    for i, emb in enumerate(embeddings):
        if emb and len(emb) == 384: # ç¡®ä¿å‘é‡ç»´åº¦æ­£ç¡®
            valid_docs.append(documents[i])
            valid_vectors.append(emb)

    # 3. ç»„è£…åˆ—å¼æ•°æ® (Columnar Format)
    # Milvus insert æ¥å£è¦æ±‚å„å­—æ®µæ•°æ®ä»¥åˆ—è¡¨å½¢å¼ä¼ å…¥
    data = [
        [doc['filename'] for doc in valid_docs],  # Scalar: æ–‡ä»¶å
        [doc['page'] for doc in valid_docs],      # Scalar: é¡µç  (ç”¨äºæº¯æº)
        [doc['chunk_id'] for doc in valid_docs],  # Scalar: åˆ‡ç‰‡ID
        [doc['content'] for doc in valid_docs],   # Scalar: åŸå§‹å†…å®¹ (ç”¨äºå…³é”®è¯æ£€ç´¢)
        valid_vectors                             # Vector: è¯­ä¹‰å‘é‡
    ]

    # 4. æ‰§è¡Œæ’å…¥ä¸æŒä¹…åŒ–
    self.collection.insert(data)
    self.collection.flush()
```

#### 2.2.3 æ··åˆæ£€ç´¢ç­–ç•¥

æ£€ç´¢å‰ï¼Œç³»ç»Ÿé¦–å…ˆåˆ©ç”¨ LLM ç”Ÿæˆçš„é—®é¢˜çš„åŒè¯­ç¿»è¯‘ï¼Œé¿å…ä¸­æ–‡é—®é¢˜è¯¢é—®è‹±æ–‡æ–‡æ¡£ï¼Œä½¿å¾—å…³é”®è¯ä¸åŒ¹é…ï¼Œä»¥æœ€å¤§åŒ–è¯­ä¹‰è¦†ç›–ã€‚éšåå¹¶è¡Œæ‰§è¡Œä¸¤è·¯æ£€ç´¢ï¼š

1. **Dense (å‘é‡æ£€ç´¢)**ï¼šæ•æ‰è¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆä¾‹å¦‚â€œç®€è°æŒ¯å­â€ä¸â€œå¼¹ç°§æŒ¯å­â€çš„è¯­ä¹‰å…³è”ï¼‰ã€‚
2. **Sparse (å…³é”®è¯æ£€ç´¢)**ï¼šå¼¥è¡¥å‘é‡æ¨¡å‹å¯¹ä¸“æœ‰åè¯æˆ–ç²¾ç¡®æ•°å­—åŒ¹é…çš„ä¸è¶³ï¼ˆä¾‹å¦‚ç²¾ç¡®åŒ¹é…å…¬å¼ä¸­çš„å˜é‡åï¼‰ã€‚

å‘é‡æ£€ç´¢å®¹æ˜“å› è¯­ä¹‰æ³›åŒ–è€Œå¬å›é”™è¯¯æ¦‚å¿µï¼ˆå¦‚â€œå¼¹ç°§æŒ¯å­â€ä¸â€œç®€è°æŒ¯å­â€ï¼‰ï¼Œè€Œå…³é”®è¯æ£€ç´¢èƒ½ç¡®ä¿ä¸“æœ‰åè¯çš„ç²¾ç¡®å‘½ä¸­ï¼Œä»è€Œå¤§å¹…æå‡å‡†ç¡®ç‡ã€‚

ç„¶åæ‰§è¡Œï¼š

- **RRF (å€’æ’èåˆ)**ï¼šç³»ç»Ÿå†…éƒ¨ä½¿ç”¨å€’æ’ç§©èåˆç®—æ³• (Reciprocal Rank Fusion) å°†ä¸¤è·¯ç»“æœåˆå¹¶ï¼Œç¡®ä¿å¤šæ ·æ€§ã€‚

<div style="display: flex; justify-content: center;">
  <img src="../images/high-precision-rag-system/RRF_flow.jpg" alt="Fig 2" style="width: 50%;">
</div>

```python
# vector_store.py ä¸­çš„æ£€ç´¢é€»è¾‘æ‘˜è¦

def search(self, query: str, top_k: int = 10, **kwargs):
   '''å‘é‡æ£€ç´¢(Dense+Keyword)+RRF èåˆ'''
   # 1. å‘é‡æ£€ç´¢ (Dense)
   dense_results = []
   query_vector = self.embedding_client.get_embedding(query) # ... (Milvus search code) ...

    # 2. å…³é”®è¯æ£€ç´¢ (Keyword)
    # é€šè¿‡ jieba åˆ†è¯åæ„å»º like "%keyword%" æŸ¥è¯¢
    keyword_results = self._keyword_search(query, top_k=top_k * 5, expr=expr)

    # 3. RRF èåˆ
    rank_dict = {}

    def apply_rrf(results_list, k=60, weight=1.0):
        for rank, item in enumerate(results_list):
            doc_id = item.get('id') or item.get('chunk_id')
            if doc_id not in rank_dict:
                rank_dict[doc_id] = {"data": item, "score": 0.0}
            # RRF æ ¸å¿ƒå…¬å¼
            rank_dict[doc_id]["score"] += weight * (1.0 / (k + rank))

    apply_rrf(dense_results, weight=4.0)
    apply_rrf(keyword_results, weight=1.0)

    # 4. æ’åºè¾“å‡º
    sorted_docs = sorted(rank_dict.values(), key=lambda x: x['score'], reverse=True)
    return [item['data'] for item in sorted_docs[:top_k * 2]]

```

### 2.3 ç»¼åˆé‡æ’åºç®—æ³•

æ£€ç´¢å›æ¥çš„ç‰‡æ®µï¼ˆChunksï¼‰éœ€è¦è¿›ä¸€æ­¥ç²¾æ’ã€‚åœ¨ `reranker_v2.py` ä¸­ï¼Œè®¾è®¡äº†ä¸€å¥—ç»¼åˆæ‰“åˆ†ç®—æ³•ã€‚
è¯„åˆ†ç»´åº¦åŒ…æ‹¬ï¼š

1. **æ¨¡ç³ŠåŒ¹é…ï¼ˆFuzzy Scoreï¼‰**ï¼šä½¿ç”¨ `fuzzywuzzy` è®¡ç®— Query ä¸ Content çš„å­—é¢é‡åˆåº¦ã€‚

2. **å…³é”®è¯è¦†ç›–ç‡ï¼ˆKeyword Coverageï¼‰**ï¼šè®¡ç®— Query ä¸­çš„æ ¸å¿ƒè¯åœ¨æ–‡æ¡£ç‰‡æ®µä¸­çš„å‡ºç°æ¯”ä¾‹ã€‚

3. **è¯­ä¹‰ç›¸ä¼¼åº¦**ï¼šæ¥è‡ª Milvus çš„åŸå§‹å‘é‡è·ç¦»ã€‚

4. **é•¿åº¦æƒ©ç½šä¸ä½ç½®åç½®**ï¼šå¯¹è¿‡çŸ­çš„ç‰‡æ®µè¿›è¡Œæƒ©ç½šï¼Œå¯¹ Milvus å¬å›çš„æ’åé å‰çš„ç‰‡æ®µç»™äºˆä½ç½®å¥–åŠ±ã€‚

5. **ä¸“æœ‰åè¯**ï¼š
   - **è‹±æ–‡ï¼ˆçœ‹â€œå¤§å°å†™â€ç‰¹å¾ï¼‰ï¼š** ä½¿ç”¨æ­£åˆ™ `\b[A-Z][a-z]+\b|[A-Z]{2,}`ï¼Œä¸“é—¨åŒ¹é…**é¦–å­—æ¯å¤§å†™**çš„å•è¯ï¼ˆå¦‚ "Milvus"ï¼‰æˆ–**å…¨å¤§å†™**çš„ç¼©å†™ï¼ˆå¦‚ "RAG"ï¼‰ï¼Œå› ä¸ºåœ¨è‹±æ–‡ä¸­è¿™äº›é€šå¸¸ä»£è¡¨ä¸“æœ‰åè¯ã€‚

   - **ä¸­æ–‡ï¼ˆçœ‹â€œè¿ç»­æ€§â€ç‰¹å¾ï¼‰ï¼š** ç”±äºä¸­æ–‡æ²¡æœ‰å¤§å°å†™ï¼Œç­–ç•¥å˜æˆäº† **â€œåˆ‡åˆ†+é•¿åº¦â€**ï¼šä½¿ç”¨éä¸­æ–‡å­—ç¬¦ä½œä¸ºåˆ†éš”ç¬¦åˆ‡æ–­å¥å­ï¼Œä¿ç•™æ‰€æœ‰è¿ç»­å‡ºç° 2 ä¸ªåŠä»¥ä¸Šçš„æ±‰å­—ç‰‡æ®µï¼ˆå¦‚â€œç®€è°æŒ¯å­â€ï¼‰ï¼Œå°†å…¶è§†ä¸ºæ½œåœ¨å®ä½“ã€‚

å…·ä½“çš„åˆ†æ•°å æ¯”è§ä¸‹å›¾ï¼š

<div style="display: flex; justify-content: center;">
   <img src="../images/high-precision-rag-system/pp-rule-rk.jpg" alt="Fig 2" style="width: 80%;">
</div>

è¿™ç§åŸºäºè§„åˆ™ä¸è¯­ä¹‰ç»“åˆçš„é‡æ’åºç­–ç•¥ï¼Œåœ¨æ— è®­ç»ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼Œæ¯”çº¯é»‘ç›’æ¨¡å‹æ›´å…·å¯è§£é‡Šæ€§ã€‚

```python
# reranker_v2.py

def _calculate_composite_score(self, query: str, chunk: Dict[str, Any]) -> float:
    content = chunk.get('content', '')

    # 1. å­—é¢é‡åˆåº¦ (FuzzyWuzzy)
    fuzzy_score = fuzz.partial_ratio(query, content)

    # 2. å…³é”®è¯è¦†ç›–ç‡
    query_keywords = self._extract_keywords(query)
    content_keywords = self._extract_keywords(content)
    keyword_coverage = (len(query_keywords & content_keywords) / len(query_keywords)) * 100 if query_keywords else 0

    # 3. å‘é‡è¯­ä¹‰åˆ† (å½’ä¸€åŒ–)
    milvus_distance = chunk.get('semantic_score', 0)
    milvus_similarity = 100 / (1 + milvus_distance * 0.1)

    # 4. é•¿åº¦æƒ©ç½š (åå¥½ 200-600 å­—çš„æ®µè½)
    content_len = len(content)
    if 200 <= content_len <= 600:
        length_score = 100
    else:
        # ... (æƒ©ç½šé€»è¾‘)
        length_score = 100 - min(50, abs(content_len - 400) / 20)

    # åŠ æƒæ±‚å’Œ
    base_score = (
        fuzzy_score * 0.25 +
        keyword_coverage * 0.25 +
        milvus_similarity * 0.35 +
        length_score * 0.15
    )

    # ä½ç½®æƒé‡
    position_bonus = 0
    if 'milvus_rank' in chunk:
        rank = chunk['milvus_rank']
        position_bonus = max(0, 20 - rank)

    # ä¸“æœ‰åè¯é¢å¤–åŠ åˆ† (Bonus)
    proper_noun_bonus = 30 if self._check_proper_nouns(query, content) else 0

    return base_score + proper_noun_bonus

```

### 2.4 API é€Ÿç‡é™åˆ¶ä¸è‡ªé€‚åº”ä¿æŠ¤

åœ¨è°ƒç”¨ LLM æˆ– Embedding æœåŠ¡æ—¶ï¼Œå¶å°”ä¼šé‡åˆ° `429 Too Many Requests`ã€‚æœ¬é¡¹ç›®åœ¨ `ernie_client.py` ä¸­å®ç°äº†è‡ªé€‚åº”é™é€Ÿæœºåˆ¶ï¼š

```Python
# é‡åˆ°é™æµæ—¶çš„å¤„ç†é€»è¾‘
if is_rate_limit:
    self._adaptive_slow_down() # æ°¸ä¹…å¢åŠ è¯·æ±‚é—´éš”
    wait_time = (2 ** attempt) + random.uniform(1.0, 3.0) # æŒ‡æ•°é€€é¿
    time.sleep(wait_time)

def _adaptive_slow_down(self):
    """è§¦å‘è‡ªé€‚åº”é™çº§ï¼šé‡åˆ°é™æµæ—¶ï¼Œæ°¸ä¹…å¢åŠ å…¨å±€è¯·æ±‚é—´éš”"""
    self.current_delay = min(self.current_delay * 2.0, 15.0)
    logger.warning(f"ğŸ“‰ è§¦å‘é€Ÿç‡é™åˆ¶(429)ï¼Œç³»ç»Ÿè‡ªåŠ¨é™é€Ÿ: æ–°é—´éš” {self.current_delay:.2f}s")
```

è¿™ä¿è¯äº†ç³»ç»Ÿåœ¨å¤§æ‰¹é‡æ–‡æ¡£å…¥åº“æ—¶çš„ç¨³å®šæ€§ã€‚

### 2.5 å¤šæ¨¡æ€é—®ç­”

é’ˆå¯¹ç§‘ç ”æ–‡æ¡£ä¸­åŒ…å«å¤§é‡å…³é”®å›¾è¡¨ï¼ˆå¦‚å®éªŒæ•°æ®ã€æ¨¡å‹æ¶æ„ï¼‰çš„ç‰¹ç‚¹ï¼Œæœ¬ç³»ç»Ÿå®ç°äº†â€œå›¾è¡¨é”å®šâ€é—®ç­”åŠŸèƒ½ã€‚æ ¸å¿ƒæŠ€æœ¯å®ç°åŒ…å«ä»¥ä¸‹ä¸‰ä¸ªç»´åº¦ï¼š

1. **ä¸Šä¸‹æ–‡å¢å¼º Prompt**
   åç«¯åœ¨æ„å»ºè¯·æ±‚æ—¶ï¼Œä¸ä»…å‘é€å›¾ç‰‡æœ¬èº«ï¼Œè¿˜æ£€ç´¢è¯¥å›¾ç‰‡æ‰€åœ¨é¡µé¢çš„ OCR æ–‡æœ¬ä½œä¸ºèƒŒæ™¯ä¿¡æ¯ï¼ˆContextï¼‰ã€‚Prompt ç»“æ„åŠ¨æ€æ‹¼è£…äº†â€œå›¾ç‰‡å…ƒæ•°æ® + èƒŒæ™¯æ–‡æœ¬ + ç”¨æˆ·é—®é¢˜â€ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹å¯¹å›¾è¡¨ç»†èŠ‚ä¸ä¸Šä¸‹æ–‡å…³è”çš„ç†è§£èƒ½åŠ›ã€‚

   ```python
   # backend.py - å¤šæ¨¡æ€é—®ç­”æ ¸å¿ƒé€»è¾‘

   # 1. æ£€ç´¢å½“å‰é¡µé¢çš„ OCR æ–‡æœ¬ä½œä¸ºèƒŒæ™¯ (Context)
   # ç³»ç»Ÿæ ¹æ®æ–‡ä»¶åå’Œé¡µç ï¼Œä» Milvus ä¸­æ‹‰å–è¯¥å›¾æ‰€åœ¨çš„å®Œæ•´é¡µé¢æ–‡æœ¬
   # page_num æ¥è‡ªå‰ç«¯å›¾ç‰‡æ–‡ä»¶åçš„è§£æ (e.g., "p3_figure.jpg" -> Page 3)
   page_text_context = milvus_store.get_page_content(doc_name, page_num)[:800]

   # 2. åŠ¨æ€æ‹¼è£… Context-Enhanced Prompt
   # å…³é”®ç‚¹ï¼šå°†"è§†è§‰ä¿¡æ¯"ä¸"æ–‡æœ¬èƒŒæ™¯"å¼ºåˆ¶å¯¹é½ï¼Œé˜²æ­¢æ¨¡å‹çœ‹å›¾è¯´è¯äº§ç”Ÿå¹»è§‰
   final_prompt = f"""
   ã€ä»»åŠ¡ã€‘ç»“åˆå›¾ç‰‡å’ŒèƒŒæ™¯ä¿¡æ¯å›ç­”é—®é¢˜ã€‚
   ã€å›¾ç‰‡å…ƒæ•°æ®ã€‘æ¥æºï¼š{doc_name} (P{page_num})
   ã€èƒŒæ™¯æ–‡æœ¬ã€‘{page_text_context} ... (æ­¤å¤„çœç•¥é•¿æ–‡æœ¬)
   ã€ç”¨æˆ·é—®é¢˜ã€‘{user_question}
   """

   # 3. å‘é€å¤šæ¨¡æ€è¯·æ±‚ (Vision API)
   # åº•å±‚ä¼šå°†å›¾ç‰‡è½¬ä¸º Base64ï¼Œä¸ final_prompt ä¸€èµ·å‘ç»™ ERNIE-VL æ¨¡å‹
   answer = ernie_client.chat_with_image(query=final_prompt, image_path=img_path)
   ```

2. **Vision æ¥å£å°è£…**
   åº•å±‚å®¢æˆ·ç«¯ï¼ˆ`ernie_client.py`ï¼‰å®ç°äº† OpenAI å…¼å®¹çš„è§†è§‰åè®®ã€‚ç³»ç»Ÿè‡ªåŠ¨è¯»å–æœ¬åœ°å›¾ç‰‡å¹¶è½¬æ¢ä¸º Base64 ç¼–ç ï¼Œé€šè¿‡ `image_url` æ ¼å¼æ„å»ºå¤šæ¨¡æ€æ¶ˆæ¯ä½“ï¼Œå®ç°äº†å›¾åƒæ•°æ®ä¸æ–‡æœ¬æŒ‡ä»¤çš„è”åˆæ¨ç†ã€‚

   ```python
   # ernie_client.py

   def chat_with_image(self, query: str, image_path: str):
      base64_image = self._encode_image(image_path)

      # æ„é€  Vision æ¶ˆæ¯æ ¼å¼
      messages = [
         {
               "role": "user",
               "content": [
                  {"type": "text", "text": query},
                  {
                     "type": "image_url",
                     "image_url": {
                           "url": f"data:image/jpeg;base64,{base64_image}"
                     }
                  }
               ]
         }
      ]
      return self.chat(messages)
   ```

3. **é™çº§ç­–ç•¥**
   ä¸ºä¿éšœç³»ç»Ÿçš„é«˜å¯ç”¨æ€§ï¼Œ`backend.py` ä¸­è®¾è®¡äº†è‡ªåŠ¨å›é€€æœºåˆ¶ã€‚è‹¥å¤šæ¨¡æ€æ¥å£è°ƒç”¨å¼‚å¸¸ï¼ˆå¦‚æ¨¡å‹ä¸æ”¯æŒæˆ–ç½‘ç»œé”™è¯¯ï¼‰ï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ•è·å¼‚å¸¸å¹¶æ— ç¼åˆ‡æ¢è‡³æ ‡å‡†æ–‡æœ¬ RAG é€šé“ï¼Œåˆ©ç”¨ OCR æ–‡æœ¬ç»§ç»­å›ç­”ï¼Œç¡®ä¿ç”¨æˆ·å¯¹è¯æµç¨‹ä¸ä¸­æ–­ã€‚

   ```python
   # backend.py ä¸­çš„é™çº§é€»è¾‘

   try:
      answer = ernie.chat_with_image(final_prompt, img_path)
      # ...
   except Exception as e:
      print(f"âš ï¸ æ¨¡å‹ä¸æ”¯æŒå›¾ç‰‡ï¼Œå‡†å¤‡åˆ‡æ¢è‡³æ–‡æœ¬æ¨¡å¼ã€‚")
      # é™çº§ï¼šä½¿ç”¨æå–å‡ºçš„æ–‡æœ¬ä½œä¸º Context ç»§ç»­é—®ç­”
      answer, metric = ask_question_logic(final_prompt, collection_name)
   ```

## 3. ç•Œé¢äº¤äº’ä¸æ•ˆæœ

### 3.1 æ·±åº¦ CSS å®šåˆ¶

å‰ç«¯åŸºäº Gradio æ­å»ºï¼ˆ`main.py`ï¼‰ï¼Œé‡‡ç”¨è‡ªå®šä¹‰ CSS (`modern_css`) æ­å»ºäº†ç¾è§‚çš„ UI ç•Œé¢ã€‚é‡ç‚¹æ”¹è¿›äº†è¾“å…¥åŒºåŸŸçš„è§†è§‰å±‚çº§ï¼šå°†é»˜è®¤çš„ç°è‰²èƒŒæ™¯æ”¹ä¸ºç™½åº•åœ†è§’å¡ç‰‡ï¼Œå¹¶ä¸ºå‘é€æŒ‰é’®æ·»åŠ äº†æ¸å˜è‰²ä¸æ‚¬æµ®é˜´å½±ï¼Œä½¿å…¶åœ¨è§†è§‰ä¸Šæ›´åŠ ç°ä»£ä¸èšç„¦ã€‚

```css
/* main.py - modern_css ç‰‡æ®µ */

/* å¼ºåˆ¶è¾“å…¥æ¡†ç™½åº•åœ†è§’ï¼Œæ¨¡æ‹Ÿç°ä»£ Chat APP */
.custom-textbox textarea {
   background-color: #ffffff !important;
   border: 1px solid #e5e7eb !important;
   border-radius: 12px !important;
   box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05) !important;
   padding: 14px !important;
}

/* æ¸å˜è‰²å‘é€æŒ‰é’® */
.send-btn {
   background: linear-gradient(135deg, #6366f1 0%, #4f46e5 100%) !important;
   color: white !important;
   box-shadow: 0 4px 10px rgba(99, 102, 241, 0.3) !important;
}
```

### 3.2 LaTeX å…¬å¼æ¸²æŸ“

ä¸ºäº†ä¿è¯å…¬å¼åœ¨ UI ç•Œé¢ä¸Šèƒ½æ­£å¸¸æ¸²æŸ“å‡ºæ¥ï¼Œé¦–å…ˆå®šä¹‰ä¸€å¥—å®Œæ•´çš„ LaTeX è¯†åˆ«è§„åˆ™ï¼Œæ¶µç›–è¡Œå†…ä¸è¡Œé—´å…¬å¼.è¿™å¥—é…ç½®è¢«åŒæ—¶é…ç½®åˆ°å¯¹è¯æ¡†ï¼ˆChatbotï¼‰å’Œæ‘˜è¦åŒºï¼ˆMarkdownï¼‰ï¼Œç¡®ä¿æ— è®ºæ˜¯æ¨¡å‹çš„å›ç­”è¿˜æ˜¯æ–‡æ¡£çš„æ‘˜è¦ï¼Œå…¬å¼éƒ½èƒ½è¢«æ¸²æŸ“ï¼š

```python
# main.py é…ç½® LaTeX è§„åˆ™
latex_config = [
    {"left": "$$", "right": "$$", "display": True},   # è¯†åˆ«è¡Œé—´å…¬å¼
    {"left": "$", "right": "$", "display": False},    # è¯†åˆ«è¡Œå†…å…¬å¼
    {"left": "\\(", "right": "\\)", "display": False}, # æ ‡å‡† LaTeX è¡Œå†…
    {"left": "\\[", "right": "\\]", "display": True}   # æ ‡å‡† LaTeX è¡Œé—´
]
```

éšåï¼Œåœ¨å®ä¾‹åŒ–ç»„ä»¶æ—¶å°†æ­¤é…ç½®æ³¨å…¥ï¼š

```python
# åœ¨ Chatbot ä¸­å¯ç”¨ LaTeX
chatbot = gr.Chatbot(
    label="Conversation",
    # ... å…¶ä»–å‚æ•° ...
    latex_delimiters=latex_config  # å…³é”®é…ç½®ï¼šå¯ç”¨å…¬å¼æ¸²æŸ“
)

# åœ¨æ‘˜è¦æ˜¾ç¤ºåŒºå¯ç”¨ LaTeX
doc_summary = gr.Markdown(
    value="*æš‚æ— æ‘˜è¦*",
    latex_delimiters=latex_config
)
```

### 3.3 å¯è§£é‡Šæ€§è®¾è®¡

åœ¨å®é™…ä½“éªŒä¸­ï¼Œä¸ºäº†æ‰“ç ´ RAG ç³»ç»Ÿçš„â€œé»‘ç›’â€å±æ€§ï¼Œæœ¬åº”ç”¨åœ¨ç•Œé¢ä¸­è®¾è®¡äº†ä¸¤ä¸ªç»´åº¦çš„è¯„ä»·æŒ‡æ ‡ï¼Œåˆ†åˆ«å¯¹åº”å¾®è§‚ä¸å®è§‚è§†è§’ï¼š

- **ç›¸å…³æ€§ (Relevance)**ï¼šå‡ºç°åœ¨èŠå¤©æ¡†çš„ã€å‚è€ƒæ¥æºã€‘åˆ—è¡¨ä¸­ã€‚è¿™æ˜¯ä¸€ä¸ª**å¾®è§‚æŒ‡æ ‡**ï¼Œå®ƒç›´æ¥å±•ç¤ºäº† `Reranker` ç»™æ¯ä¸€ä¸ªå…·ä½“æ–‡æ¡£åˆ‡ç‰‡æ‰“å‡ºçš„ `composite_score`ï¼ˆåŸºäºå‘é‡+å…³é”®è¯+è§„åˆ™çš„ç»¼åˆå¾—åˆ†ï¼‰ã€‚å®ƒçš„ä½œç”¨æ˜¯å‘Šè¯‰ç”¨æˆ·ï¼š_â€œä¸ºä»€ä¹ˆç³»ç»Ÿå¼•ç”¨äº†ç¬¬ 3 é¡µè¿™æ®µè¯ï¼Œè€Œä¸æ˜¯ç¬¬ 5 é¡µé‚£æ®µï¼Ÿâ€_

```python
# backend.py - æ„å»ºå‚è€ƒæ¥æºåˆ—è¡¨
sources = "\n\nğŸ“š **å‚è€ƒæ¥æº:**\n"
for c in final:
    # ... (å»é‡é€»è¾‘) ...
    # ç›´æ¥ Reranker è®¡ç®—å‡ºçš„å•ç‰‡å¾—åˆ†
    sources += f"- {key} [ç›¸å…³æ€§:{c.get('composite_score',0):.0f}%]\n"
```

- **ç½®ä¿¡åº¦ (Confidence)**ï¼šå±•ç¤ºåœ¨ã€åˆ†æè¯¦æƒ…ã€‘é¢æ¿ä¸­ã€‚è¿™æ˜¯ä¸€ä¸ª**å®è§‚æŒ‡æ ‡**ï¼Œç³»ç»Ÿæå– **Top-1 åˆ‡ç‰‡**çš„å¾—åˆ†å¹¶è¿›è¡Œå½’ä¸€åŒ–ï¼ˆCapped at 100%ï¼‰ä½œä¸ºæœ¬æ¬¡é—®ç­”çš„æ•´ä½“è¯„åˆ†ã€‚å®ƒçš„ä½œç”¨æ˜¯é¢„è­¦ï¼š_â€œç³»ç»Ÿå¯¹è‡ªå·±ç”Ÿæˆçš„ç­”æ¡ˆæœ‰å¤šå¤§æŠŠæ¡ï¼Ÿâ€_ å¦‚æœç½®ä¿¡åº¦ä½äº 60%ï¼Œå³ä¾¿æ¨¡å‹ç”Ÿæˆçš„æ–‡å­—å†é€šé¡ºï¼Œç”¨æˆ·ä¹Ÿåº”è­¦æƒ•å¯èƒ½å­˜åœ¨çš„â€œå¹»è§‰â€é£é™©ã€‚

```python
# backend.py - è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
# 1. è·å–é‡æ’åºåçš„ Top-1 ç‰‡æ®µ
final = processed[:22]
top_score = final[0].get('composite_score', 0) if final else 0

# 2. å½’ä¸€åŒ–å¤„ç† (å°é¡¶ 100%)ï¼Œä½œä¸ºæœ¬æ¬¡é—®ç­”çš„"ç½®ä¿¡åº¦"
metric = f"{min(100, top_score):.1f}%"
```

å®ç°çš„ UI ç•Œé¢æ•ˆæœå¦‚ä¸‹ï¼Œåœ¨å›ç­”ä¸­æ˜¾ç¤ºäº†ç›¸åº”æ¥æºå‘é‡çš„é¡µæ•°å’Œç›¸å…³æ€§ï¼š
![Fig 4ï¼šæ‘˜è¦å’Œå›¾è¡¨](../images/high-precision-rag-system/sys-UI-1-1.jpg)
![Fig 5ï¼šé€‰æ‹©å›¾è¡¨é—®ç­”](../images/high-precision-rag-system/sys-UI-1-2.jpg)
![Fig 6ï¼šå…¨éƒ¨æ–‡æ¡£æ£€ç´¢](../images/high-precision-rag-system/sys-UI-1-3.jpg)
![Fig 7ï¼šçŸ¥è¯†åº“ç®¡ç†](../images/high-precision-rag-system/sys-UI-2.jpg)
![Fig 8ï¼šç³»ç»Ÿé…ç½®](../images/high-precision-rag-system/sys-UI-3.jpg)

## 4. æ€»ç»“

### 4.1 åŠŸèƒ½äº®ç‚¹

- **é«˜ç²¾åº¦é—®ç­”**ï¼šé›†æˆ ç™¾åº¦æ–‡å¿ƒä¸€è¨€ï¼ˆERNIE Botï¼‰ å¤§æ¨¡å‹ APIï¼Œåˆ©ç”¨ ERNIE å¤§æ¨¡å‹å“è¶Šçš„è¯­ä¹‰ç†è§£ä¸ç”Ÿæˆèƒ½åŠ›ï¼Œé…åˆâ€œå‘é‡+å…³é”®è¯â€åŒè·¯æ··åˆæ£€ç´¢ä¸ RRF é‡æ’åºç®—æ³•ï¼Œç¡®ä¿å›ç­”çš„ç²¾å‡†åº¦ä¸é²æ£’æ€§ã€‚
- **å¤šçŸ¥è¯†åº“ç®¡ç†**ï¼šæ”¯æŒåŠ¨æ€åˆ›å»ºã€åˆ‡æ¢å’Œåˆ é™¤çŸ¥è¯†åº“ã€‚
- **å¬å›ç‡è‡ªæµ‹**ï¼šå†…ç½® `test_self_recall` å‡½æ•°ï¼Œè‡ªåŠ¨ä»åº“ä¸­æŠ½å–æ ·æœ¬éªŒè¯æ£€ç´¢å‡†ç¡®ç‡ã€‚
- **å®æ—¶åé¦ˆ**ï¼šä¸Šä¼ å¤§æ–‡ä»¶æ—¶ï¼Œé€šè¿‡è¿›åº¦æ¡å®æ—¶æ˜¾ç¤º OCR è§£æä¸ Embedding å…¥åº“è¿›åº¦ã€‚

### 4.2 æœªæ¥æ”¹è¿›

é€šè¿‡ç»“åˆ Milvus çš„å‘é‡èƒ½åŠ›ä¸ä¼ ç»Ÿçš„å…³é”®è¯åŒ¹é…æŠ€æœ¯ï¼Œå¹¶è¾…ä»¥ç»†ç²’åº¦çš„é‡æ’åºç­–ç•¥ï¼Œæœ¬ç³»ç»Ÿåœ¨ä½æˆæœ¬ä¸‹å®ç°äº†è¾ƒé«˜ç²¾åº¦çš„æ–‡æ¡£é—®ç­”ã€‚æœªæ¥çš„ä¼˜åŒ–æ–¹å‘å°†é›†ä¸­åœ¨ï¼š

- å¼•å…¥æœ¬åœ° BGE-Reranker æ¨¡å‹æ›¿ä»£è§„åˆ™æ‰“åˆ†ã€‚
- åˆ©ç”¨æå–çš„å›¾ç‰‡ä¿¡æ¯å¢å¼ºå¤šæ¨¡æ€é—®ç­”èƒ½åŠ›ã€‚

## è‡´è°¢

è¡·å¿ƒæ„Ÿè°¢å¼ æ™¶è€å¸ˆå¸®åŠ©æˆ‘ç†è§£é¡¹ç›®éœ€è¦å®ç°çš„ç›®æ ‡ï¼Œå¹¶ç»™äºˆåœ¨ç³»ç»Ÿè®¾è®¡ä¸å®ç°ç»†èŠ‚ä¸Šçš„æŒ‡å¯¼ï¼Œä½¿å¾—æˆ‘èƒ½å¤Ÿå®Œæˆé¡¹ç›®ã€‚

æ„Ÿè°¢æ¨æœ‰å¿—è€å¸ˆåœ¨æ˜Ÿæ²³ç¤¾åŒºéƒ¨ç½²ä¸Šçº¿è¿‡ç¨‹ä¸­çš„å¤§åŠ›æ”¯æŒã€‚

æ„Ÿè°¢ææˆé¾™è€å¸ˆåœ¨ Milvus å‘é‡æ£€ç´¢æ–¹é¢æå‡ºçš„å»ºè®®ã€‚

å¾ˆè£å¹¸å‚ä¸å¯èˆªè®¡åˆ’ï¼ˆç¬¬ 6 æœŸï¼‰ï¼Œæœªæ¥æˆ‘å°†æŒç»­æ·±è€•ï¼Œä¸ºå¼€æºç¤¾åŒºè´¡çŒ®æ›´å¤šåŠ›é‡ã€‚
